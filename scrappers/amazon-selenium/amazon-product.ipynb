{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping Amazon Product Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver import ChromeOptions\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load list of product urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"urls.txt\",'r') as urls_txt:\n",
    "    urllist = urls_txt.read().splitlines()\n",
    "print(urllist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-time setup of Chrome WebDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ChromeOptions() \n",
    "options.headless = False # Due to dynamic elements cannot run headless\n",
    "driver = webdriver.Chrome(chrome_options=options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through Product List Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.jsonl','w') as output:\n",
    "    \n",
    "    for url in urllist:\n",
    "        \n",
    "        # Product url and asin\n",
    "        print(\"Product url: \" + url)\n",
    "        asin = url[-10:]\n",
    "        print(\"Product sku: \" + asin)\n",
    "        \n",
    "        # Load product page\n",
    "        driver.get(url)\n",
    "\n",
    "        # Click all image/video thumbnails to load dynamic elements\n",
    "        alt_imgs = driver.find_element(By.XPATH, \"//div[@id='altImages']\")\n",
    "        lst_item = alt_imgs.find_elements(By.XPATH, \".//li[contains(@class, 'imageThumbnail') or contains(@class, 'videoThumbnail')]//input\")\n",
    "        for item in lst_item:\n",
    "            item.click()\n",
    "            sleep(0.5)\n",
    "        \n",
    "        # Collect image/video urls for posterior download\n",
    "        lst_imgs = driver.find_elements(By.XPATH, \"//div[@class='imgTagWrapper']/img\")\n",
    "        try:\n",
    "            video = driver.find_element(By.XPATH, \"//div[@id='main-video-container']//video\")\n",
    "            lst_imgs.append(video)\n",
    "        except NoSuchElementException:\n",
    "            print(\"This product has no associated video\")\n",
    "        lst_srcs = [img.get_attribute('src') for img in lst_imgs]\n",
    "        print(lst_srcs)\n",
    "        print(\"List size: \", len(lst_srcs))\n",
    "\n",
    "        # Get more product data: title, price, bullets\n",
    "        title = driver.find_element(By.XPATH, \"//span[@id='productTitle']\").get_attribute(\"innerHTML\").strip()\n",
    "        print(title)\n",
    "        price = driver.find_element(By.XPATH, \"//span[@class='a-offscreen']\").get_attribute(\"innerHTML\").strip()\n",
    "        print(price)\n",
    "        lst_bullets = driver.find_elements(By.XPATH, \"//div[@id='feature-bullets']//li/span\")\n",
    "        print(f'Number of span-bullets: {len(lst_bullets)}')\n",
    "        \n",
    "        # Create list of bullet points describing the product. \n",
    "        # Remove whatever spurious html element is left in the text\n",
    "        lst_bullets_text = []\n",
    "        for bul in lst_bullets:\n",
    "            b = bul.get_attribute('innerHTML').strip()\n",
    "            soup = BeautifulSoup(b, 'html.parser')\n",
    "            lst_bullets_text.append(soup.get_text())\n",
    "            #lst_bullets_text = [bul.get_attribute('innerHTML').strip() for bul in lst_bullets]\n",
    "        print(lst_bullets_text)\n",
    "\n",
    "        # Create object and write to jsonl file\n",
    "        product = {\n",
    "            'title': title,\n",
    "            'asin': asin,\n",
    "            'price': price,\n",
    "            'bullets': lst_bullets_text,\n",
    "            'media': lst_srcs\n",
    "        }\n",
    "\n",
    "        # Serialize the object as JSON and write it to the file\n",
    "        json.dump(product, output)\n",
    "        # Write a newline character after each object\n",
    "        output.write('\\n')\n",
    "\n",
    "        # Create folders for each product and write metadata file\n",
    "        if not os.path.exists(asin):\n",
    "            os.mkdir(asin)\n",
    "        else:\n",
    "            print(\"Folder already exists!\")               \n",
    "        prod_file = asin + '/' + asin + '.json' \n",
    "        with open(prod_file, 'w') as pf:    \n",
    "            json.dump(product, pf)\n",
    "        \n",
    "        # Download product media files to folder\n",
    "        for url in lst_srcs: \n",
    "            r = requests.get(url)\n",
    "            if r.status_code == 200:\n",
    "                fpath = asin + '/' + url.split(\"/\")[-1].split(\"?\")[0]\n",
    "                with open(fpath, 'wb') as fm:\n",
    "                    fm.write(r.content)\n",
    "            else:\n",
    "                print(\"Error downloading media\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ceadb5fac282510284e1f97e5ef88dfb91c26c99322e3fead01a0172e1d5903"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
